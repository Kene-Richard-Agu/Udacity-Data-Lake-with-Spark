# Udacity-Data-Lake-with-Spark
This project required me to build an ETL pipeline for a data lake hosted on S3. To complete the project, I had to load data from S3, process the data into analytics tables using Spark, and load them back into S3. I deployed this Spark process on a cluster using AWS.
